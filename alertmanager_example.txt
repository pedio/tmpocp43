####################################################
## 1) create alertmanger yaml file
cat <<EOF > alertmanager.yaml
global:
  resolve_timeout: 5m
  smtp_smarthost: 'smtphost:25'
  smtp_from: 'dba@example.com'
  #smtp_auth_username: 'xxx@example.com'
  #smtp_auth_password: 'your_email_password'
 
route:
  group_by:
  - job
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  receiver: default
  routes:
  - match:
      alertname: Watchdog
    repeat_interval: 5m
    receiver: watchdog
  - match:
      severity: critical
    repeat_interval: 12h
    receiver: ocpadmin
receivers:
- name: default
  email_configs:
  - to: dba@example.com
- name: watchdog
- name: ocpadmin
  email_configs:
  - to: dba@example.com
EOF


## 2) apply alertmanger setting
oc -n openshift-monitoring create secret generic alertmanager-main --from-file=alertmanager.yaml --dry-run -o=yaml |  oc -n openshift-monitoring replace secret --filename=-

## 3) delete alertmanager pod to reload configuration
[root@bastion alertmanager]# oc delete po -l alertmanager=main -n openshift-monitoring
pod "alertmanager-main-0" deleted
pod "alertmanager-main-1" deleted
pod "alertmanager-main-2" deleted

## 4) verify the alertmanger pod to see if any error on send alerts
[root@bastion alertmanager]# oc logs -f alertmanager-main-0 -c alertmanager -n openshift-monitoring
level=info ts=2020-04-24T04:55:26.114Z caller=main.go:217 msg="Starting Alertmanager" version="(version=0.19.0, branch=rhaos-4.3-rhel-7, revision=d837d9961cb7921448ec703fa6487af7c4f0c72d)"
level=info ts=2020-04-24T04:55:26.114Z caller=main.go:218 build_context="(go=go1.12.12, user=root@ef10ed2c7861, date=20200302-08:26:27)"
level=warn ts=2020-04-24T04:55:26.134Z caller=cluster.go:228 component=cluster msg="failed to join cluster" err="3 errors occurred:\n\t* Failed to resolve alertmanager-main-0.alertmanager-operated.openshift-monitoring.svc:9094: lookup alertmanager-main-0.alertmanager-operated.openshift-monitoring.svc on 172.30.0.10:53: no such host\n\t* Failed to resolve alertmanager-main-1.alertmanager-operated.openshift-monitoring.svc:9094: lookup alertmanager-main-1.alertmanager-operated.openshift-monitoring.svc on 172.30.0.10:53: no such host\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated.openshift-monitoring.svc:9094: lookup alertmanager-main-2.alertmanager-operated.openshift-monitoring.svc on 172.30.0.10:53: no such host\n\n"
level=info ts=2020-04-24T04:55:26.134Z caller=cluster.go:230 component=cluster msg="will retry joining cluster every 10s"
level=warn ts=2020-04-24T04:55:26.134Z caller=main.go:308 msg="unable to join gossip mesh" err="3 errors occurred:\n\t* Failed to resolve alertmanager-main-0.alertmanager-operated.openshift-monitoring.svc:9094: lookup alertmanager-main-0.alertmanager-operated.openshift-monitoring.svc on 172.30.0.10:53: no such host\n\t* Failed to resolve alertmanager-main-1.alertmanager-operated.openshift-monitoring.svc:9094: lookup alertmanager-main-1.alertmanager-operated.openshift-monitoring.svc on 172.30.0.10:53: no such host\n\t* Failed to resolve alertmanager-main-2.alertmanager-operated.openshift-monitoring.svc:9094: lookup alertmanager-main-2.alertmanager-operated.openshift-monitoring.svc on 172.30.0.10:53: no such host\n\n"
level=info ts=2020-04-24T04:55:26.135Z caller=cluster.go:623 component=cluster msg="Waiting for gossip to settle..." interval=2s
level=info ts=2020-04-24T04:55:26.196Z caller=coordinator.go:119 component=configuration msg="Loading configuration file" file=/etc/alertmanager/config/alertmanager.yaml
level=info ts=2020-04-24T04:55:26.197Z caller=coordinator.go:131 component=configuration msg="Completed loading of configuration file" file=/etc/alertmanager/config/alertmanager.yaml
level=info ts=2020-04-24T04:55:26.203Z caller=main.go:466 msg=Listening address=127.0.0.1:9093
level=info ts=2020-04-24T04:55:28.135Z caller=cluster.go:648 component=cluster msg="gossip not settled" polls=0 before=0 now=1 elapsed=2.000254552s
level=info ts=2020-04-24T04:55:36.138Z caller=cluster.go:640 component=cluster msg="gossip settled; proceeding" elapsed=10.002905776s
